{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de15d03c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad22251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "from pypdf import PdfReader\n",
    "import datefinder\n",
    "from rapidfuzz import process\n",
    "from dateutil import parser as date_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da46a1a4",
   "metadata": {},
   "source": [
    "Load Vendor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a93fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCEL_PATH = r\"PATH_TO_YOUR_EXCEL_FILE.xlsx\" # Replace with the actual path to your Excel file\n",
    "rm_df = pd.read_excel(EXCEL_PATH, sheet_name=\"Sheet Name\", header=1) # Enter actual sheet name, change header to 0 if the first row is the header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be65bf",
   "metadata": {},
   "source": [
    "Shared Utility Functions. Make sure the parameter names line up with how you format the excel file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3975a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initials(full_name):\n",
    "    return ''.join([part[0].upper() for part in str(full_name).split() if part])\n",
    "\n",
    "def get_rm_initials(company_name): \n",
    "    row = rm_df[rm_df['Vendor Name'].str.lower() == company_name.lower()]\n",
    "    if not row.empty:\n",
    "        rm_name = row.iloc[0]['Relationship Manager']\n",
    "        return get_initials(rm_name)\n",
    "    return 'XX'\n",
    "\n",
    "def get_last_modified_date(filepath):\n",
    "    timestamp = os.path.getmtime(filepath)\n",
    "    return datetime.fromtimestamp(timestamp).strftime('%Y%m%d')\n",
    "\n",
    "def detect_doc_type(filename):  # if loops are in order of specificity to generality\n",
    "    name = filename.lower()\n",
    "    if \"a\" in name or \"b\" in name:\n",
    "        return \"c\"\n",
    "    elif \"d\" in name or \"e\" in name:\n",
    "        return \"f\"\n",
    "    # ... Add more specific checks as needed\n",
    "    else:\n",
    "        return \"g\" # Default case\n",
    "\n",
    "def guess_vendor_from_filename_or_ird(filename, vendor_list, ird_list):\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    # Regex for ID: optional apostrophe, 4 digits, optional letter, optional apostrophe, e.g. '5097', '5097A', 5097A, etc.\n",
    "    id_match = re.search(r\"'?\\s*(\\d{4}[A-Za-z]?)\\s*'?\", base)\n",
    "    if id_match:\n",
    "        ird_candidate = id_match.group(1)\n",
    "        # Try to match ID in DataFrame (case-insensitive, strip spaces)\n",
    "        row = rm_df[rm_df['Id'].astype(str).str.replace(\"'\", \"\").str.strip().str.lower() == ird_candidate.lower()]\n",
    "        if not row.empty:\n",
    "            return row.iloc[0]['Vendor Name']\n",
    "    # Fallback: vendor name guessing\n",
    "    words = re.split(r'[\\s\\-_\\.]+', base)\n",
    "    ignore = {'words'} # Add common legal/document type words that might skew guessing\n",
    "    vendor_guess = ' '.join([w for w in words if w.lower() not in ignore and not w.isdigit() and not re.match(r'\\d{4}', w)])\n",
    "    match = process.extractOne(vendor_guess, vendor_list, score_cutoff=60)\n",
    "    return match[0] if match else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96d0d9",
   "metadata": {},
   "source": [
    "Draft Naming Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb749ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240909-ISO-UnknownVendor-VSAL-XX\n"
     ]
    }
   ],
   "source": [
    "def build_draft_filename_auto(filepath):\n",
    "    vendor_names = rm_df['Vendor Name'].tolist()\n",
    "    ird_list = rm_df['Id'].astype(str).tolist()\n",
    "    guessed_vendor = guess_vendor_from_filename_or_ird(os.path.basename(filepath), vendor_names, ird_list)\n",
    "    if guessed_vendor is None:\n",
    "        guessed_vendor = \"UnknownVendor\"\n",
    "    draft_date = get_last_modified_date(filepath)\n",
    "    doc_type = detect_doc_type(os.path.basename(filepath))\n",
    "    rm_initials = get_rm_initials(guessed_vendor)\n",
    "    return f\"{draft_date}-My Company Name-{guessed_vendor}-{doc_type}-{rm_initials}\" # Alter this format as needed.\n",
    "filepath = r\"\" #path to your file you'd like to rename\n",
    "new_name = build_draft_filename_auto(filepath)\n",
    "print(new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd342f",
   "metadata": {},
   "source": [
    "Executed (PDF) Naming Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200fd8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug - Doc type: VSAL\n",
      "Debug - First 200 chars: Ed. 12/2023 1 VERISK STRATEGIC ALLIANCES LICENSE AGREEMENT, including all Annexes attached hereto (the \"Agreement \"), dated August 27, 2024, between Insurance Services Office, Inc., with its principal\n",
      "Debug - Fallback date selected: 2024-08-27 00:00:00\n",
      "Generated filename: 20240827-ISO-UnknownVendor-VSAL\n"
     ]
    }
   ],
   "source": [
    "#Extracting potential date strings with more specific formats\n",
    "def extract_date_strings(text):\n",
    "    patterns = [\n",
    "        # ISO format dates (most reliable)\n",
    "        r'\\b\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}\\b',\n",
    "        # US format MM/DD/YYYY\n",
    "        r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b',\n",
    "        # Written dates like \"January 12, 2025\"\n",
    "        r'\\b(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{1,2}(?:st|nd|rd|th)?,?\\s+\\d{4}\\b',\n",
    "        # Abbreviated months \"Jan 12, 2025\"\n",
    "        r'\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\.?\\s+\\d{1,2}(?:st|nd|rd|th)?,?\\s+\\d{4}\\b',\n",
    "        # Day first format \"12 January 2025\"\n",
    "        r'\\b\\d{1,2}(?:st|nd|rd|th)?\\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}\\b',\n",
    "    ]\n",
    "\n",
    "    all_dates = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        all_dates.extend(matches)\n",
    "    return all_dates\n",
    "\n",
    "#Parse dates and filter out obviously wrong ones\n",
    "def parse_and_validate_dates(date_strings):\n",
    "    valid_dates = []\n",
    "    current_year = datetime.now().year\n",
    "\n",
    "    for date_str in date_strings:\n",
    "        try:\n",
    "            parsed_date = date_parser.parse(date_str, fuzzy=False)\n",
    "            if 1990 <= parsed_date.year <= current_year + 10:\n",
    "                valid_dates.append(parsed_date)\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    return valid_dates\n",
    "\n",
    "# Look for patterns like \"effective as of\", \"is effective\", etc.\n",
    "def find_effective_date_context(text):\n",
    "    effective_patterns = [\n",
    "        r'effective\\s+(?:as\\s+of\\s+)?([^.]{0,50}(?:\\d{1,2}[/-]\\d{1,2}[/-]\\d{4}|\\w+\\s+\\d{1,2},?\\s+\\d{4})[^.]{0,20})',\n",
    "        r'(?:shall\\s+be\\s+)?effective\\s+(?:on\\s+)?([^.]{0,50}(?:\\d{1,2}[/-]\\d{1,2}[/-]\\d{4}|\\w+\\s+\\d{1,2},?\\s+\\d{4})[^.]{0,20})',\n",
    "        r'(?:agreement|contract|document)\\s+(?:is\\s+)?effective\\s+([^.]{0,50}(?:\\d{1,2}[/-]\\d{1,2}[/-]\\d{4}|\\w+\\s+\\d{1,2},?\\s+\\d{4})[^.]{0,20})'\n",
    "    ]\n",
    "\n",
    "    for pattern in effective_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "        if match:\n",
    "            context = match.group(1)\n",
    "            dates = extract_date_strings(context)\n",
    "            if dates:\n",
    "                parsed = parse_and_validate_dates(dates)\n",
    "                if parsed:\n",
    "                    return max(parsed)  # Return latest date in effective context\n",
    "    return None\n",
    "\n",
    "#Big kahuna\n",
    "def select_pdf_date_for_naming(filepath):\n",
    "    try:\n",
    "        doc_type = detect_doc_type(os.path.basename(filepath))\n",
    "        with open(filepath, 'rb') as f:\n",
    "            reader = PdfReader(f)\n",
    "            first_page_text = \"\"\n",
    "            last_page_text = \"\"\n",
    "            if len(reader.pages) > 0:\n",
    "                first_page_text = reader.pages[0].extract_text() or \"\"\n",
    "            if len(reader.pages) > 1:\n",
    "                last_page_text = reader.pages[-1].extract_text() or \"\"\n",
    "            else:\n",
    "                last_page_text = first_page_text\n",
    "\n",
    "            # Clean up extracted text\n",
    "            first_page_clean = re.sub(r'\\s+', ' ', first_page_text.strip())\n",
    "            last_page_clean = re.sub(r'\\s+', ' ', last_page_text.strip())\n",
    "            # Debugging output, helps to know where it pulled the date from without opening the PDF\n",
    "            print(f\"Debug - Doc type: {doc_type}\")\n",
    "            print(f\"Debug - First 200 chars: {first_page_clean[:200]}\")\n",
    "\n",
    "            # Priority 1: For Annex documents, prioritize first page\n",
    "            if doc_type and doc_type.startswith(\"Annex\"):\n",
    "                dates = parse_and_validate_dates(extract_date_strings(first_page_clean))\n",
    "                if dates:\n",
    "                    selected_date = min(dates)  # Use earliest date for Annex\n",
    "                    print(f\"Debug - Annex date selected: {selected_date}\")\n",
    "                    return selected_date.strftime('%Y%m%d')\n",
    "        \n",
    "            # Priority 2: Look for effective date context\n",
    "            effective_date = find_effective_date_context(first_page_clean + \" \" + last_page_clean)\n",
    "            if effective_date:\n",
    "                print(f\"Debug - Found effective date: {effective_date}\")\n",
    "                return effective_date.strftime('%Y%m%d')\n",
    "\n",
    "            # Priority 3: Look for signature dates (usually on last page)\n",
    "            signature_context = re.search(r'(?:signed|executed|dated).*?([^.]{0,100})', last_page_clean, re.IGNORECASE)\n",
    "            if signature_context:\n",
    "                sig_dates = parse_and_validate_dates(extract_date_strings(signature_context.group(1)))\n",
    "                if sig_dates:\n",
    "                    selected_date = max(sig_dates)\n",
    "                    print(f\"Debug - Signature date selected: {selected_date}\")\n",
    "                    return selected_date.strftime('%Y%m%d')\n",
    "\n",
    "            # If all else fails, fallback to all dates, prefer later ones\n",
    "            all_dates = parse_and_validate_dates(\n",
    "                extract_date_strings(first_page_clean) + \n",
    "                extract_date_strings(last_page_clean)\n",
    "            )\n",
    "            if all_dates:\n",
    "                unique_dates = list(set(all_dates))\n",
    "                unique_dates.sort()\n",
    "                selected_date = max(unique_dates)\n",
    "                print(f\"Debug - Fallback date selected: {selected_date}\")\n",
    "                return selected_date.strftime('%Y%m%d')\n",
    "            # If no valid dates found, return \"Review\", debug lets me know the failure was in finding a date\n",
    "            print(\"Debug - No valid dates found\")\n",
    "            return \"Review\"\n",
    "     # and if any error occurs, return \"Review\" to avoid breaking the process\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF {filepath}: {str(e)}\")\n",
    "        return \"Review\"\n",
    "\n",
    "def build_executed_filename_auto(filepath):\n",
    "    \"\"\"Build filename for executed documents\"\"\"\n",
    "    vendor_names = rm_df['Vendor Name'].tolist()\n",
    "    ird_list = rm_df['Ird Id'].astype(str).tolist()\n",
    "    guessed_vendor = guess_vendor_from_filename_or_ird(\n",
    "        os.path.basename(filepath), vendor_names, ird_list\n",
    "    )\n",
    "    if guessed_vendor is None:\n",
    "        guessed_vendor = \"UnknownVendor\"\n",
    "    eff_date = select_pdf_date_for_naming(filepath)\n",
    "    doc_type = detect_doc_type(os.path.basename(filepath))\n",
    "    return f\"{eff_date}-ISO-{guessed_vendor}-{doc_type}\"\n",
    "\n",
    "pdf_path = r\"\" #Path to your PDF file\n",
    "new_pdf_name = build_executed_filename_auto(pdf_path)\n",
    "print(f\"Generated filename: {new_pdf_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
